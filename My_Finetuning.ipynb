{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IG6fwukq5oSe"
      },
      "source": [
        "# Load your data\n",
        "\n",
        "Before finetuning a pretrained model of the experiments we provide in our repository (or precomputed and provided [here](https://datacloud.hhi.fraunhofer.de/nextcloud/s/NCjYws3mamLrkKq)), first load your custom 100 Hz sampled 12-lead ECG signal data `X` of shape `[N,L,12]` in Millivolts (mV) and multi-hot encoded labels `y` of shape `[N,C]` as numpy arrays, where `C` is the number of classes and `N` the number of total samples in this dataset. Although PTB-XL comes with fixed `L=1000` (i,e. 10 seconds), it is not required to be fixed, **BUT** the shortest sample must be longer than `input_size` of the specific model (e.g. 2.5 seconds for our fastai-models).\n",
        "\n",
        "For proper tinetuning split your data into four numpy arrays: `X_train`,`y_train`,`X_val` and `y_val`\n",
        "\n",
        "### Example: finetune model trained on all (71) on superdiagnostic (5)\n",
        "Below we provide an example for loading [PTB-XL](https://physionet.org/content/ptb-xl/1.0.1/) aggregated at the `superdiagnostic` level, where we use the provided folds for train-validation-split:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0L-abXib6HkK",
        "outputId": "f1f52165-be2b-43a1-deef-487ad092e24f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting wfdb\n",
            "  Downloading wfdb-4.1.0-py3-none-any.whl (159 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.9/159.9 KB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0.0,>=1.10.1 in /usr/local/lib/python3.8/dist-packages (from wfdb) (1.21.6)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from wfdb) (1.7.3)\n",
            "Requirement already satisfied: SoundFile<0.12.0,>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from wfdb) (0.11.0)\n",
            "Requirement already satisfied: pandas<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from wfdb) (1.3.5)\n",
            "Requirement already satisfied: matplotlib<4.0.0,>=3.2.2 in /usr/local/lib/python3.8/dist-packages (from wfdb) (3.2.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.8.1 in /usr/local/lib/python3.8/dist-packages (from wfdb) (2.25.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib<4.0.0,>=3.2.2->wfdb) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib<4.0.0,>=3.2.2->wfdb) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib<4.0.0,>=3.2.2->wfdb) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib<4.0.0,>=3.2.2->wfdb) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas<2.0.0,>=1.0.0->wfdb) (2022.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.8.1->wfdb) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.8.1->wfdb) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.8.1->wfdb) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.8.1->wfdb) (2.10)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.8/dist-packages (from SoundFile<0.12.0,>=0.10.0->wfdb) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi>=1.0->SoundFile<0.12.0,>=0.10.0->wfdb) (2.21)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib<4.0.0,>=3.2.2->wfdb) (1.15.0)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9674 sha256=9ee2ac4220cf0050bbe1ff61078358ae5d397aff8bc8735d071f55a5e1653f46\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/a8/c3/3cf2c14a1837a4e04bd98631724e81f33f462d86a1d895fae0\n",
            "Successfully built wget\n",
            "Installing collected packages: wget, wfdb\n",
            "Successfully installed wfdb-4.1.0 wget-3.2\n"
          ]
        }
      ],
      "source": [
        "!pip install wget wfdb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jqxss_rS6Jxn"
      },
      "outputs": [],
      "source": [
        "import wget\n",
        "import numpy as np\n",
        "import os\n",
        "import zipfile\n",
        "import tensorflow as tf\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AcjcSuO06o-6",
        "outputId": "af36b0d7-b30a-467a-d49b-c929e10ce9a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-01-04 13:54:56--  https://physionet.org/static/published-projects/ptb-xl/ptb-xl-a-large-publicly-available-electrocardiography-dataset-1.0.1.zip\n",
            "Resolving physionet.org (physionet.org)... 18.18.42.54\n",
            "Connecting to physionet.org (physionet.org)|18.18.42.54|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1842722380 (1.7G) [application/zip]\n",
            "Saving to: ‘ptb-xl-a-large-publicly-available-electrocardiography-dataset-1.0.1.zip’\n",
            "\n",
            "ptb-xl-a-large-publ 100%[===================>]   1.72G  11.7MB/s    in 2m 29s  \n",
            "\n",
            "2023-01-04 13:57:26 (11.8 MB/s) - ‘ptb-xl-a-large-publicly-available-electrocardiography-dataset-1.0.1.zip’ saved [1842722380/1842722380]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://physionet.org/static/published-projects/ptb-xl/ptb-xl-a-large-publicly-available-electrocardiography-dataset-1.0.1.zip\n",
        "\n",
        "os.mkdir(\"./data/\")\n",
        "\n",
        "\n",
        "with zipfile.ZipFile(\"./ptb-xl-a-large-publicly-available-electrocardiography-dataset-1.0.1.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"./data/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eTAXTEV86rEj"
      },
      "outputs": [],
      "source": [
        "with zipfile.ZipFile(\"./ptb-xl-a-large-publicly-available-electrocardiography-dataset-1.0.1.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"./data/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Qv9hVm-5wyi",
        "outputId": "b34def82-b6f9-4cc9-d408-50ffce572ce3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting GitPython\n",
            "  Downloading GitPython-3.1.30-py3-none-any.whl (184 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.0/184.0 KB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 KB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: smmap, gitdb, GitPython\n",
            "Successfully installed GitPython-3.1.30 gitdb-4.0.10 smmap-5.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install GitPython\n",
        "from git import Repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u4T-c5KI5y2W"
      },
      "outputs": [],
      "source": [
        "HTTPS_REMOTE_URL = 'https://github.com/Bsingstad/ecg_ptbxl_benchmarking.git'\n",
        "DEST_NAME = 'github_repo'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8hm-j6751kC",
        "outputId": "16cfb00e-d530-4761-d56e-4ce8993fbfbb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<git.repo.base.Repo '/content/github_repo/.git'>"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Repo.clone_from(HTTPS_REMOTE_URL, DEST_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "SRUZICm6562J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0022dad4-3beb-42d3-e4eb-8cd2d975a3ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "from github_repo.code import *\n",
        "%matplotlib inline\n",
        "%load_ext autoreload"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aiM4gNgv5_V2"
      },
      "outputs": [],
      "source": [
        "/content/data/ptb-xl-a-large-publicly-available-electrocardiography-dataset-1.0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CmW7xaR_5oSf",
        "outputId": "22fa5cc9-454a-4fbb-f3b2-e3c7b586854d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((19267, 1000, 12), (19267, 5), (2163, 1000, 12), (2163, 5))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "from github_repo.code.utils import utils\n",
        "\n",
        "sampling_frequency=100\n",
        "datafolder='./data/ptb-xl-a-large-publicly-available-electrocardiography-dataset-1.0.1/'\n",
        "task='superdiagnostic'\n",
        "outputfolder='./github_repo/output/'\n",
        "\n",
        "\n",
        "# Load PTB-XL data\n",
        "data, raw_labels = utils.load_dataset(datafolder, sampling_frequency)\n",
        "# Preprocess label data\n",
        "labels = utils.compute_label_aggregations(raw_labels, datafolder, task)\n",
        "# Select relevant data and convert to one-hot\n",
        "#data, labels, Y, _ = utils.select_data(data, labels, task, min_samples=0, outputfolder=outputfolder)\n",
        "\n",
        "data, labels, Y, _ = utils.select_data(data, labels, task, min_samples=0, outputfolder=outputfolder)\n",
        "\n",
        "# 1-9 for training \n",
        "X_train = data[labels.strat_fold < 10]\n",
        "y_train = Y[labels.strat_fold < 10]\n",
        "# 10 for validation\n",
        "X_val = data[labels.strat_fold == 10]\n",
        "y_val = Y[labels.strat_fold == 10]\n",
        "\n",
        "num_classes = 5         # <=== number of classes in the finetuning dataset\n",
        "input_shape = [1000,12] # <=== shape of samples, [None, 12] in case of different lengths\n",
        "\n",
        "X_train.shape, y_train.shape, X_val.shape, y_val.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1UyIF9kv5oSg"
      },
      "source": [
        "# Train or download models\n",
        "There are two possibilities:\n",
        "   1. Run the experiments as described in README. Afterwards you find trained in models in `output/expX/models/`\n",
        "   2. Download the precomputed `output`-folder with all experiments and models from [here]((https://datacloud.hhi.fraunhofer.de/nextcloud/s/NCjYws3mamLrkKq))\n",
        "\n",
        "# Load pretrained model\n",
        "\n",
        "For loading a pretrained model:\n",
        "   1. specify `modelname` which can be seen in `code/configs/` (e.g. `modelname='fastai_xresnet1d101'`)\n",
        "   2. provide `experiment` to build the path `pretrainedfolder` (here: `exp0` refers to the experiment with `all` 71 SCP-statements)\n",
        "   \n",
        "This returns the pretrained model where the classification is replaced by a random initialized head with the same number of outputs as the number of classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEx-BdLJ5oSh",
        "outputId": "8e58d9a2-d158-4478-af6c-e4ad1966ba63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inception model built.\n"
          ]
        }
      ],
      "source": [
        "from github_repo.code.models.your_model import inception_time_model\n",
        "\n",
        "experiment = 'exp0'\n",
        "modelname = 'fastai_xresnet1d101'\n",
        "pretrainedfolder = '../output/'+experiment+'/models/'+modelname+'/'\n",
        "mpath='../output/' # <=== path where the finetuned model will be stored\n",
        "n_classes_pretrained = 71 # <=== because we load the model from exp0, this should be fixed because this depends the experiment\n",
        "\n",
        "model = inception_time_model(\"tf_inception\", num_classes, sampling_frequency, mpath, input_shape)\n",
        "\n",
        "#model = fastai_model(\n",
        "#    modelname, \n",
        "#    num_classes, \n",
        "#    sampling_frequency, \n",
        "#    mpath, \n",
        "#    input_shape=input_shape, \n",
        "#    pretrainedfolder=pretrainedfolder,\n",
        "#    n_classes_pretrained=n_classes_pretrained, \n",
        "#    pretrained=True,\n",
        "#    epochs_finetuning=2,\n",
        "#)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6dtMWU15oSh"
      },
      "source": [
        "# Preprocess data with pretrained Standardizer\n",
        "\n",
        "Since we standardize inputs to zero mean and unit variance, your custom data needs to be standardized with the respective mean and variance. This is also provided in the respective experiment folder `output/expX/data/standard_scaler.pkl`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "uqSSsK_V5oSh"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "from github_repo.code.utils import utils\n",
        "\n",
        "standard_scaler = pickle.load(open('./github_repo/output/'+experiment+'/data/standard_scaler.pkl', \"rb\"))\n",
        "\n",
        "X_train = utils.apply_standardizer(X_train, standard_scaler)\n",
        "X_val = utils.apply_standardizer(X_val, standard_scaler)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfdlaRZr5oSh"
      },
      "source": [
        "# Finetune model\n",
        "\n",
        "Calling `model.fit` of a model with `pretrained=True` will perform finetuning as proposed in our work i.e. **gradual unfreezing and discriminative learning rates**. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "MxzCOgaP5oSi",
        "outputId": "a516c2b7-c7e7-4aec-ef63-fd4cb070f57e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 1/30\n",
            "603/603 [==============================] - 217s 338ms/step - loss: 0.3309 - binary_accuracy: 0.8579 - ROC: 0.8877 - PRC: 0.7383 - val_loss: 0.3352 - val_binary_accuracy: 0.8607 - val_ROC: 0.9058 - val_PRC: 0.7844 - lr: 0.0010\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 2/30\n",
            "319/603 [==============>...............] - ETA: 1:33 - loss: 0.2876 - binary_accuracy: 0.8797 - ROC: 0.9170 - PRC: 0.7969"
          ]
        }
      ],
      "source": [
        "model.fit(X_train, y_train, X_val, y_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvnNlyCX5oSi"
      },
      "source": [
        "# Evaluate model on validation data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m1rgPocD5oSi",
        "outputId": "6d91d6ab-7d00-4433-cdbd-2d7fd083cdaa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "aggregating predictions...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>macro_auc</th>\n",
              "      <th>Fmax</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.931458</td>\n",
              "      <td>0.827961</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   macro_auc      Fmax\n",
              "0   0.931458  0.827961"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_val_pred = model.predict(X_val)\n",
        "utils.evaluate_experiment(y_val, y_val_pred)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.7.4 64-bit ('ecg_python37': conda)",
      "language": "python",
      "name": "python37464bitecgpython37condacca13046f89242bdbe235da55b7380ab"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}