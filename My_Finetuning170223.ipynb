{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IG6fwukq5oSe"
      },
      "source": [
        "# Load your data\n",
        "\n",
        "Before finetuning a pretrained model of the experiments we provide in our repository (or precomputed and provided [here](https://datacloud.hhi.fraunhofer.de/nextcloud/s/NCjYws3mamLrkKq)), first load your custom 100 Hz sampled 12-lead ECG signal data `X` of shape `[N,L,12]` in Millivolts (mV) and multi-hot encoded labels `y` of shape `[N,C]` as numpy arrays, where `C` is the number of classes and `N` the number of total samples in this dataset. Although PTB-XL comes with fixed `L=1000` (i,e. 10 seconds), it is not required to be fixed, **BUT** the shortest sample must be longer than `input_size` of the specific model (e.g. 2.5 seconds for our fastai-models).\n",
        "\n",
        "For proper tinetuning split your data into four numpy arrays: `X_train`,`y_train`,`X_val` and `y_val`\n",
        "\n",
        "### Example: finetune model trained on all (71) on superdiagnostic (5)\n",
        "Below we provide an example for loading [PTB-XL](https://physionet.org/content/ptb-xl/1.0.1/) aggregated at the `superdiagnostic` level, where we use the provided folds for train-validation-split:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0L-abXib6HkK",
        "outputId": "35e28bc5-ef4d-4049-c602-0b35e8b02800"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: wget in /usr/local/lib/python3.8/dist-packages (3.2)\n",
            "Requirement already satisfied: wfdb in /usr/local/lib/python3.8/dist-packages (4.1.0)\n",
            "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.8/dist-packages (0.19.0)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from wfdb) (1.7.3)\n",
            "Requirement already satisfied: pandas<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from wfdb) (1.3.5)\n",
            "Requirement already satisfied: matplotlib<4.0.0,>=3.2.2 in /usr/local/lib/python3.8/dist-packages (from wfdb) (3.2.2)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.10.1 in /usr/local/lib/python3.8/dist-packages (from wfdb) (1.21.6)\n",
            "Requirement already satisfied: SoundFile<0.12.0,>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from wfdb) (0.11.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.8.1 in /usr/local/lib/python3.8/dist-packages (from wfdb) (2.25.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow-addons) (23.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.8/dist-packages (from tensorflow-addons) (2.7.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib<4.0.0,>=3.2.2->wfdb) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib<4.0.0,>=3.2.2->wfdb) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib<4.0.0,>=3.2.2->wfdb) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib<4.0.0,>=3.2.2->wfdb) (3.0.9)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas<2.0.0,>=1.0.0->wfdb) (2022.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.8.1->wfdb) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.8.1->wfdb) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.8.1->wfdb) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.8.1->wfdb) (4.0.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.8/dist-packages (from SoundFile<0.12.0,>=0.10.0->wfdb) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi>=1.0->SoundFile<0.12.0,>=0.10.0->wfdb) (2.21)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib<4.0.0,>=3.2.2->wfdb) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install wget wfdb tensorflow-addons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4NQeLDBZUlm",
        "outputId": "6e80f07e-9549-402b-8046-6d2970b28bc9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Jqxss_rS6Jxn"
      },
      "outputs": [],
      "source": [
        "import wget\n",
        "import numpy as np\n",
        "import os\n",
        "import zipfile\n",
        "import tensorflow as tf\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import pickle\n",
        "import tensorflow_addons as tfa\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import StratifiedKFold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "AcjcSuO06o-6"
      },
      "outputs": [],
      "source": [
        "!wget https://physionet.org/static/published-projects/ptb-xl/ptb-xl-a-large-publicly-available-electrocardiography-dataset-1.0.1.zip\n",
        "\n",
        "os.mkdir(\"./data/\")\n",
        "\n",
        "\n",
        "with zipfile.ZipFile(\"./ptb-xl-a-large-publicly-available-electrocardiography-dataset-1.0.1.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"./data/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Qv9hVm-5wyi",
        "outputId": "1f46551e-a54b-4640-da13-ea8f0c56cd10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting GitPython\n",
            "  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 KB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 KB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: smmap, gitdb, GitPython\n",
            "Successfully installed GitPython-3.1.31 gitdb-4.0.10 smmap-5.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install GitPython\n",
        "from git import Repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "u4T-c5KI5y2W"
      },
      "outputs": [],
      "source": [
        "HTTPS_REMOTE_URL = 'https://github.com/Bsingstad/ecg_ptbxl_benchmarking.git'\n",
        "DEST_NAME = 'github_repo'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8hm-j6751kC",
        "outputId": "7571e604-d6f4-4f3c-f5c3-0dd1ba5ca4aa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<git.repo.base.Repo '/content/github_repo/.git'>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "Repo.clone_from(HTTPS_REMOTE_URL, DEST_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "SRUZICm6562J"
      },
      "outputs": [],
      "source": [
        "from github_repo.code import *\n",
        "%matplotlib inline\n",
        "%load_ext autoreload"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CmW7xaR_5oSf",
        "outputId": "2380fbee-9312-49ee-949e-276d0dcf1b47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 21837/21837 [00:55<00:00, 393.75it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((19634, 1000, 12), (19634, 71), (2203, 1000, 12), (2203, 71))"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "from github_repo.code.utils import utils\n",
        "\n",
        "sampling_frequency=100\n",
        "datafolder='./data/ptb-xl-a-large-publicly-available-electrocardiography-dataset-1.0.1/'\n",
        "task='all'\n",
        "outputfolder='./github_repo/output/'\n",
        "\n",
        "\n",
        "# Load PTB-XL data\n",
        "data, raw_labels = utils.load_dataset(datafolder, sampling_frequency)\n",
        "# Preprocess label data\n",
        "labels = utils.compute_label_aggregations(raw_labels, datafolder, task)\n",
        "# Select relevant data and convert to one-hot\n",
        "#data, labels, Y, _ = utils.select_data(data, labels, task, min_samples=0, outputfolder=outputfolder)\n",
        "\n",
        "data, labels, Y, _ = utils.select_data(data, labels, task, min_samples=0, outputfolder=outputfolder)\n",
        "\n",
        "# 1-9 for training \n",
        "X_train = data[labels.strat_fold < 10]\n",
        "y_train = Y[labels.strat_fold < 10]\n",
        "# 10 for validation\n",
        "X_val = data[labels.strat_fold == 10]\n",
        "y_val = Y[labels.strat_fold == 10]\n",
        "\n",
        "num_classes = y_train.shape[1]    # <=== number of classes in the finetuning dataset\n",
        "input_shape = [1000,12] # <=== shape of samples, [None, 12] in case of different lengths\n",
        "\n",
        "X_train.shape, y_train.shape, X_val.shape, y_val.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "DIKpffEJMllK",
        "outputId": "20d28be0-a801-4c65-c611-7116d44b3f8c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAVf0lEQVR4nO3dfYxd9X3n8fenOOSBVtjArMXa1tpVLCKyWh46AqJEVYs3xpAq5g8aEVXFQl55/3B3k1WlLuxKi0oSiUir0kTaIFnBrYmyEEqTxSIo1OtQVV2Jh+EhBHBYT3iobQGeYkN2g8rW9Lt/3N+QizPD3MF3Zq593i/p6p7zPb977veYy+fc+d0zd1JVSJK64VeWugFJ0uIx9CWpQwx9SeoQQ1+SOsTQl6QOWbbUDbyXc845p9auXbvUbUjSSeWxxx77+6oam2nbSIf+2rVrmZiYWOo2JOmkkuSl2bYNNL2T5D8keSbJ00nuTPKhJOuSPJxkMsl3kpzexn6wrU+27Wv79nNjqz+X5IoTPTBJ0vzMGfpJVgH/Hhivqn8JnAZcC3wVuLWqPgocBba2h2wFjrb6rW0cSc5vj/s4sAn4RpLThns4kqT3MugHucuADydZBnwEeBm4HLinbd8FXN2WN7d12vYNSdLqd1XVW1X1AjAJXHLihyBJGtScoV9Vh4D/CvwdvbB/A3gMeL2qjrVhB4FVbXkVcKA99lgbf3Z/fYbHvCPJtiQTSSampqbezzFJkmYxyPTOCnrv0tcB/xw4g970zIKoqh1VNV5V42NjM374LEl6nwaZ3vnXwAtVNVVV/wh8F/gksLxN9wCsBg615UPAGoC2/Uzgtf76DI+RJC2CQUL/74DLknykzc1vAJ4FHgSuaWO2APe25d1tnbb9h9X7Ks/dwLXt6p51wHrgkeEchiRpEHNep19VDye5B3gcOAY8AewAvg/cleTLrXZ7e8jtwLeSTAJH6F2xQ1U9k+RueieMY8D2qnp7yMcjSXoPGeXv0x8fHy9/OUuS5ifJY1U1PtO2kf6NXEnDtfaG779r/cVbPrNEnWip+IVrktQhhr4kdYihL0kdYuhLUocY+pLUIYa+JHWIoS9JHWLoS1KHGPqS1CGGviR1iKEvSR1i6EtShxj6ktQhhr4kdYihL0kdYuhLUocY+pLUIXOGfpLzkjzZd/tZki8mOSvJniT72/2KNj5Jvp5kMslTSS7u29eWNn5/ki2zP6skaSHMGfpV9VxVXVhVFwK/AbwJfA+4AdhbVeuBvW0d4EpgfbttA24DSHIWcBNwKXAJcNP0iUKStDjmO72zAfhpVb0EbAZ2tfou4Oq2vBm4o3oeApYnORe4AthTVUeq6iiwB9h0wkcgSRrYfEP/WuDOtryyql5uy68AK9vyKuBA32MOttps9XdJsi3JRJKJqampebYnSXovA4d+ktOBzwJ/cfy2qiqghtFQVe2oqvGqGh8bGxvGLiVJzXze6V8JPF5Vr7b1V9u0De3+cKsfAtb0PW51q81WlyQtkvmE/uf5xdQOwG5g+gqcLcC9ffXr2lU8lwFvtGmgB4CNSVa0D3A3tpokaZEsG2RQkjOATwP/tq98C3B3kq3AS8DnWv1+4Cpgkt6VPtcDVNWRJF8CHm3jbq6qIyd8BJKkgQ0U+lX1c+Ds42qv0bua5/ixBWyfZT87gZ3zb1OSNAz+Rq4kdYihL0kdYuhLUocY+pLUIYa+JHWIoS9JHWLoS1KHGPqS1CGGviR1iKEvSR1i6EtShxj6ktQhhr4kdYihL0kdYuhLUocY+pLUIYa+JHXIQKGfZHmSe5L8JMm+JJ9IclaSPUn2t/sVbWySfD3JZJKnklzct58tbfz+JFtmf0ZJ0kIY9J3+14AfVNXHgAuAfcANwN6qWg/sbesAVwLr220bcBtAkrOAm4BLgUuAm6ZPFJKkxTFn6Cc5E/hN4HaAqvp/VfU6sBnY1YbtAq5uy5uBO6rnIWB5knOBK4A9VXWkqo4Ce4BNQz0aSdJ7GuSd/jpgCvizJE8k+WaSM4CVVfVyG/MKsLItrwIO9D3+YKvNVpckLZJBQn8ZcDFwW1VdBPycX0zlAFBVBdQwGkqyLclEkompqalh7FKS1AwS+geBg1X1cFu/h95J4NU2bUO7P9y2HwLW9D1+davNVn+XqtpRVeNVNT42NjafY5EkzWHO0K+qV4ADSc5rpQ3As8BuYPoKnC3AvW15N3Bdu4rnMuCNNg30ALAxyYr2Ae7GVpMkLZJlA477d8C3k5wOPA9cT++EcXeSrcBLwOfa2PuBq4BJ4M02lqo6kuRLwKNt3M1VdWQoRyFJGshAoV9VTwLjM2zaMMPYArbPsp+dwM75NChJGh5/I1eSOsTQl6QOMfQlqUMMfUnqEENfkjrE0JekDjH0JalDDH1J6hBDX5I6xNCXpA4x9CWpQwx9SeoQQ1+SOsTQl6QOMfQlqUMMfUnqEENfkjrE0JekDhko9JO8mOTHSZ5MMtFqZyXZk2R/u1/R6kny9SSTSZ5KcnHffra08fuTbJnt+SRJC2M+7/R/u6ourKrpv5V7A7C3qtYDe9s6wJXA+nbbBtwGvZMEcBNwKXAJcNP0iUKStDhOZHpnM7CrLe8Cru6r31E9DwHLk5wLXAHsqaojVXUU2ANsOoHnlyTN06ChX8BfJXksybZWW1lVL7flV4CVbXkVcKDvsQdbbbb6uyTZlmQiycTU1NSA7UmSBrFswHGfqqpDSf4ZsCfJT/o3VlUlqWE0VFU7gB0A4+PjQ9mnJKlnoHf6VXWo3R8GvkdvTv7VNm1Duz/chh8C1vQ9fHWrzVaXJC2SOUM/yRlJfm16GdgIPA3sBqavwNkC3NuWdwPXtat4LgPeaNNADwAbk6xoH+BubDVJ0iIZZHpnJfC9JNPj/3tV/SDJo8DdSbYCLwGfa+PvB64CJoE3gesBqupIki8Bj7ZxN1fVkaEdiSRpTnOGflU9D1wwQ/01YMMM9QK2z7KvncDO+bcpSRoGfyNXkjrE0JekDjH0JalDDH1J6hBDX5I6xNCXpA4x9CWpQwx9SeoQQ1+SOsTQl6QOMfQlqUMMfUnqEENfkjrE0JekDjH0JalDDH1J6hBDX5I6ZODQT3JakieS3NfW1yV5OMlkku8kOb3VP9jWJ9v2tX37uLHVn0tyxbAPRpL03ubzTv8LwL6+9a8Ct1bVR4GjwNZW3wocbfVb2ziSnA9cC3wc2AR8I8lpJ9a+JGk+Bgr9JKuBzwDfbOsBLgfuaUN2AVe35c1tnbZ9Qxu/Gbirqt6qqhfo/eH0S4ZxEJKkwQz6Tv9PgT8C/qmtnw28XlXH2vpBYFVbXgUcAGjb32jj36nP8BhJ0iKYM/ST/A5wuKoeW4R+SLItyUSSiampqcV4SknqjEHe6X8S+GySF4G76E3rfA1YnmRZG7MaONSWDwFrANr2M4HX+uszPOYdVbWjqsaranxsbGzeByRJmt2coV9VN1bV6qpaS++D2B9W1e8BDwLXtGFbgHvb8u62Ttv+w6qqVr+2Xd2zDlgPPDK0I5EkzWnZ3ENm9R+Bu5J8GXgCuL3Vbwe+lWQSOELvREFVPZPkbuBZ4BiwvarePoHnlyTN07xCv6r+Gvjrtvw8M1x9U1X/APzuLI//CvCV+TYpSRoOfyNXkjrE0JekDjH0JalDDH1J6hBDX5I6xNCXpA4x9CWpQwx9SeoQQ1+SOsTQl6QOMfQlqUMMfUnqEENfkjrE0JekDjH0JalDDH1J6hBDX5I6xNCXpA6ZM/STfCjJI0l+lOSZJH/c6uuSPJxkMsl3kpze6h9s65Nt+9q+fd3Y6s8luWKhDkqSNLNB3um/BVxeVRcAFwKbklwGfBW4tao+ChwFtrbxW4GjrX5rG0eS8+n9kfSPA5uAbyQ5bZgHI0l6b3OGfvX837b6gXYr4HLgnlbfBVzdlje3ddr2DUnS6ndV1VtV9QIwyQx/WF2StHAGmtNPclqSJ4HDwB7gp8DrVXWsDTkIrGrLq4ADAG37G8DZ/fUZHtP/XNuSTCSZmJqamv8RSZJmNVDoV9XbVXUhsJreu/OPLVRDVbWjqsaranxsbGyhnkaSOmleV+9U1evAg8AngOVJlrVNq4FDbfkQsAagbT8TeK2/PsNjJEmLYJCrd8aSLG/LHwY+DeyjF/7XtGFbgHvb8u62Ttv+w6qqVr+2Xd2zDlgPPDKsA5EkzW3Z3EM4F9jVrrT5FeDuqrovybPAXUm+DDwB3N7G3w58K8kkcITeFTtU1TNJ7gaeBY4B26vq7eEezolZe8P337X+4i2fWaJOJGlhzBn6VfUUcNEM9eeZ4eqbqvoH4Hdn2ddXgK/Mv01J0jD4G7mS1CGGviR1iKEvSR1i6EtShxj6ktQhhr4kdYihL0kdYuhLUocY+pLUIYa+JHWIoS9JHWLoS1KHGPqS1CGGviR1iKEvSR1i6EtShxj6ktQhhr4kdcggfxh9TZIHkzyb5JkkX2j1s5LsSbK/3a9o9ST5epLJJE8lubhvX1va+P1Jtsz2nJKkhTHIO/1jwB9W1fnAZcD2JOcDNwB7q2o9sLetA1wJrG+3bcBt0DtJADcBl9L727o3TZ8oJEmLY87Qr6qXq+rxtvx/gH3AKmAzsKsN2wVc3ZY3A3dUz0PA8iTnAlcAe6rqSFUdBfYAm4Z6NJKk9zSvOf0ka4GLgIeBlVX1ctv0CrCyLa8CDvQ97GCrzVY//jm2JZlIMjE1NTWf9iRJcxg49JP8KvCXwBer6mf926qqgBpGQ1W1o6rGq2p8bGxsGLuUJDUDhX6SD9AL/G9X1Xdb+dU2bUO7P9zqh4A1fQ9f3Wqz1SVJi2SQq3cC3A7sq6o/6du0G5i+AmcLcG9f/bp2Fc9lwBttGugBYGOSFe0D3I2tJklaJMsGGPNJ4PeBHyd5stX+E3ALcHeSrcBLwOfatvuBq4BJ4E3geoCqOpLkS8CjbdzNVXVkKEchSRrInKFfVX8LZJbNG2YYX8D2Wfa1E9g5nwYlScPjb+RKUocY+pLUIYa+JHWIoS9JHWLoS1KHGPqS1CGGviR1iKEvSR1i6EtShxj6ktQhhr4kdYihL0kdYuhLUocY+pLUIYa+JHWIoS9JHWLoS1KHDPI3cncmOZzk6b7aWUn2JNnf7le0epJ8PclkkqeSXNz3mC1t/P4kW2Z6LknSwhrknf6fA5uOq90A7K2q9cDetg5wJbC+3bYBt0HvJAHcBFwKXALcNH2iGHVrb/j+OzdJOtnNGfpV9TfA8X/AfDOwqy3vAq7uq99RPQ8By5OcC1wB7KmqI1V1FNjDL59IJEkL7P3O6a+sqpfb8ivAyra8CjjQN+5gq81W/yVJtiWZSDIxNTX1PtuTJM3khD/IraoCagi9TO9vR1WNV9X42NjYsHYrSeL9h/6rbdqGdn+41Q8Ba/rGrW612eqSpEX0fkN/NzB9Bc4W4N6++nXtKp7LgDfaNNADwMYkK9oHuBtbTdIC8kIEHW/ZXAOS3An8FnBOkoP0rsK5Bbg7yVbgJeBzbfj9wFXAJPAmcD1AVR1J8iXg0Tbu5qo6/sNhSdICmzP0q+rzs2zaMMPYArbPsp+dwM55dSdJGip/I1eSOsTQl6QOmXN652TW/+HVi7d8Zgk7kaTRcEqH/qg6/koKT0iSFouhr3cZ5Z+ORrk36WThnL4kdYihL0kdYuhLUoc4py+dID+Y18nE0JdOUp5s9H4Y+tIcvGpIpxLn9CWpQwx9SeoQp3dGlFMKkhaCoS/N06l2Qp7v8fgB8snN6R1J6hDf6Z8kfHf1y061d9zSYjD0F4BhJGlULXroJ9kEfA04DfhmVd2y2D0Mk+/AJZ1MFjX0k5wG/Dfg08BB4NEku6vq2cXs41R1/E8Yg/zEMdeYmU5qw/hJZql+Gnqvf6Nh9vJ+jm++/y2G9bzqlsV+p38JMFlVzwMkuQvYDCxK6M/1P/z72cewHrMYV1CM8k8lwwjjYZygFuskMMjzdD3AR+mEfCpJVS3ekyXXAJuq6t+09d8HLq2qP+gbsw3Y1lbPA547wac9B/j7E9zHYrHXhWGvC8NeF8Ywev0XVTU204aR+yC3qnYAO4a1vyQTVTU+rP0tJHtdGPa6MOx1YSx0r4t9nf4hYE3f+upWkyQtgsUO/UeB9UnWJTkduBbYvcg9SFJnLer0TlUdS/IHwAP0LtncWVXPLPDTDm2qaBHY68Kw14VhrwtjQXtd1A9yJUlLy+/ekaQOMfQlqUNO6dBPsinJc0kmk9yw1P30S7IzyeEkT/fVzkqyJ8n+dr9iKXuclmRNkgeTPJvkmSRfaPWR6zfJh5I8kuRHrdc/bvV1SR5ur4XvtAsJllyS05I8keS+tj6SfQIkeTHJj5M8mWSi1UbuNQCQZHmSe5L8JMm+JJ8YxV6TnNf+PadvP0vyxYXs9ZQN/b6vfLgSOB/4fJLzl7ard/lzYNNxtRuAvVW1Htjb1kfBMeAPq+p84DJge/u3HMV+3wIur6oLgAuBTUkuA74K3FpVHwWOAluXsMd+XwD29a2Pap/TfruqLuy7jnwUXwPQ+36vH1TVx4AL6P0bj1yvVfVc+/e8EPgN4E3geyxkr1V1St6ATwAP9K3fCNy41H0d1+Na4Om+9eeAc9vyucBzS93jLH3fS+/7k0a6X+AjwOPApfR+w3HZTK+NJexvdfsf+nLgPiCj2Gdfvy8C5xxXG7nXAHAm8ALtQpVR7vW4/jYC/2uhez1l3+kDq4ADfesHW22Urayql9vyK8DKpWxmJknWAhcBDzOi/bYpkyeBw8Ae4KfA61V1rA0ZldfCnwJ/BPxTWz+b0exzWgF/leSx9nUpMJqvgXXAFPBnbersm0nOYDR77XctcGdbXrBeT+XQP6lV7xQ/UtfTJvlV4C+BL1bVz/q3jVK/VfV29X5cXk3vS/4+tsQt/ZIkvwMcrqrHlrqXefhUVV1Mb8p0e5Lf7N84Qq+BZcDFwG1VdRHwc46bHhmhXgFon918FviL47cNu9dTOfRPxq98eDXJuQDt/vAS9/OOJB+gF/jfrqrvtvLI9gtQVa8DD9KbJlmeZPqXEUfhtfBJ4LNJXgTuojfF8zVGr893VNWhdn+Y3rzzJYzma+AgcLCqHm7r99A7CYxir9OuBB6vqlfb+oL1eiqH/sn4lQ+7gS1teQu9ufMllyTA7cC+qvqTvk0j12+SsSTL2/KH6X32sI9e+F/Thi15r1V1Y1Wtrqq19F6bP6yq32PE+pyW5Iwkvza9TG/++WlG8DVQVa8AB5Kc10ob6H19+8j12ufz/GJqBxay16X+8GKBPxi5Cvjf9OZ0//NS93Ncb3cCLwP/SO+dyVZ6c7p7gf3A/wTOWuo+W6+fovfj5VPAk+121Sj2C/wr4InW69PAf2n1XwceASbp/Qj9waXuta/n3wLuG+U+W18/ardnpv9/GsXXQOvrQmCivQ7+B7BihHs9A3gNOLOvtmC9+jUMktQhp/L0jiTpOIa+JHWIoS9JHWLoS1KHGPqS1CGGviR1iKEvSR3y/wGsL3ZkWYw+FwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.bar(np.unique(y_train.argmax(axis=1),return_counts=True)[0],np.unique(y_train.argmax(axis=1),return_counts=True)[1])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "-a6LeAwqOm_i"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "_, X_grid, _, y_grid= train_test_split(X_train, y_train, test_size=0.10, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QW5xSWezMWo-",
        "outputId": "93b74274-7428-4dcc-c95e-3d15fe2c9b85"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1964, 1000, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "X_grid.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "fDz352LpQNds",
        "outputId": "bc810a87-821e-468c-b57d-3343a4f310bb"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.bar(np.unique(y_grid.argmax(axis=1),return_counts=True)[0],np.unique(y_grid.argmax(axis=1),return_counts=True)[1])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1UyIF9kv5oSg"
      },
      "source": [
        "# Train or download models\n",
        "There are two possibilities:\n",
        "   1. Run the experiments as described in README. Afterwards you find trained in models in `output/expX/models/`\n",
        "   2. Download the precomputed `output`-folder with all experiments and models from [here]((https://datacloud.hhi.fraunhofer.de/nextcloud/s/NCjYws3mamLrkKq))\n",
        "\n",
        "# Load pretrained model\n",
        "\n",
        "For loading a pretrained model:\n",
        "   1. specify `modelname` which can be seen in `code/configs/` (e.g. `modelname='fastai_xresnet1d101'`)\n",
        "   2. provide `experiment` to build the path `pretrainedfolder` (here: `exp0` refers to the experiment with `all` 71 SCP-statements)\n",
        "   \n",
        "This returns the pretrained model where the classification is replaced by a random initialized head with the same number of outputs as the number of classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "kg7-fD1ocLBB"
      },
      "outputs": [],
      "source": [
        "from github_repo.code.models.base_model import ClassificationModel\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "        \n",
        "class inception_time_model(ClassificationModel):\n",
        "    def __init__(self, name, n_classes,  sampling_frequency, outputfolder, input_shape, epoch=30, batch_size=32, lr_init = 0.001, lr_red=\"yes\", model_depth=6, loss=\"bce\", kernel_size=40, bottleneck_size=32, nb_filters=32, clf=\"binary\", verbose=0):\n",
        "        super(inception_time_model, self).__init__()\n",
        "        self.name = name\n",
        "        self.n_classes = n_classes\n",
        "        self.sampling_frequency = sampling_frequency\n",
        "        self.outputfolder = outputfolder\n",
        "        self.input_shape = input_shape\n",
        "        if loss == \"bce\":\n",
        "          self.loss = tf.keras.losses.BinaryCrossentropy()\n",
        "        elif loss == \"wbce\":\n",
        "          self.loss = tfa.losses.SigmoidFocalCrossEntropy() #focal instead of weighted bce\n",
        "        self.model = build_model((self.sampling_frequency*10,12),self.n_classes,lr_init = lr_init, depth=model_depth, kernel_size=kernel_size, bottleneck_size=bottleneck_size, nb_filters=nb_filters,clf=clf, loss=self.loss)\n",
        "        self.epoch = epoch\n",
        "        self.batch_size = batch_size\n",
        "        self.lr_red = lr_red\n",
        "        self.verbose = verbose\n",
        "\n",
        "        \n",
        "        \n",
        "\n",
        "    def fit(self, X_train, y_train, X_val, y_val):\n",
        "\n",
        "        if self.lr_red == \"no\":\n",
        "            self.model.fit(X_train, y_train, epochs=self.epoch, batch_size=self.batch_size, \n",
        "            validation_data=(X_val, y_val), verbose=self.verbose)\n",
        "        elif self.lr_red == \"yes\":\n",
        "            self.model.fit(X_train, y_train, epochs=self.epoch, batch_size=self.batch_size, \n",
        "            validation_data=(X_val, y_val), verbose=self.verbose,\n",
        "            callbacks = [tf.keras.callbacks.LearningRateScheduler(scheduler, verbose=0)])\n",
        "        else:\n",
        "            print(\"Error: wrong lr_red argument\")\n",
        "\n",
        "    \n",
        "    def fit_tf(self, traindata, valdata):\n",
        "\n",
        "        if self.lr_red == \"no\":\n",
        "            self.model.fit(traindata, epochs=self.epoch, batch_size=self.batch_size, \n",
        "            validation_data=valdata, verbose=self.verbose)\n",
        "        elif self.lr_red == \"yes\":\n",
        "            self.model.fit(traindata, epochs=self.epoch, batch_size=self.batch_size, \n",
        "            validation_data=valdata, verbose=self.verbose,\n",
        "            callbacks = [tf.keras.callbacks.LearningRateScheduler(scheduler, verbose=0)])\n",
        "        else:\n",
        "            print(\"Error: wrong lr_red argument\")\n",
        "\n",
        "        #self.model.save(self.outputfolder +'last_model.h5')\n",
        "    def predict(self, X):\n",
        "        return self.model.predict(X)\n",
        "\n",
        "\n",
        "def _inception_module(input_tensor, stride=1, activation='linear', use_bottleneck=True, kernel_size=40, bottleneck_size=32, nb_filters=32):\n",
        "\n",
        "    if use_bottleneck and int(input_tensor.shape[-1]) > 1:\n",
        "        input_inception = tf.keras.layers.Conv1D(filters=bottleneck_size, kernel_size=1,\n",
        "                                              padding='same', activation=activation, use_bias=False)(input_tensor)\n",
        "    else:\n",
        "        input_inception = input_tensor\n",
        "\n",
        "    # kernel_size_s = [3, 5, 8, 11, 17]\n",
        "    kernel_size_s = [kernel_size // (2 ** i) for i in range(3)]\n",
        "\n",
        "    conv_list = []\n",
        "\n",
        "    for i in range(len(kernel_size_s)):\n",
        "        conv_list.append(tf.keras.layers.Conv1D(filters=nb_filters, kernel_size=kernel_size_s[i],\n",
        "                                              strides=stride, padding='same', activation=activation, use_bias=False)(\n",
        "            input_inception))\n",
        "\n",
        "    max_pool_1 = tf.keras.layers.MaxPool1D(pool_size=3, strides=stride, padding='same')(input_tensor)\n",
        "\n",
        "    conv_6 = tf.keras.layers.Conv1D(filters=nb_filters, kernel_size=1,\n",
        "                                  padding='same', activation=activation, use_bias=False)(max_pool_1)\n",
        "\n",
        "    conv_list.append(conv_6)\n",
        "\n",
        "    x = tf.keras.layers.Concatenate(axis=2)(conv_list)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.Activation(activation='relu')(x)\n",
        "    return x\n",
        "\n",
        "def _shortcut_layer(input_tensor, out_tensor):\n",
        "    shortcut_y = tf.keras.layers.Conv1D(filters=int(out_tensor.shape[-1]), kernel_size=1,\n",
        "                                      padding='same', use_bias=False)(input_tensor)\n",
        "    shortcut_y = tf.keras.layers.BatchNormalization()(shortcut_y)\n",
        "\n",
        "    x = tf.keras.layers.Add()([shortcut_y, out_tensor])\n",
        "    x = tf.keras.layers.Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "def build_model(input_shape, nb_classes, depth=6, use_residual=True, lr_init = 0.001, kernel_size=40, bottleneck_size=32, nb_filters=32, clf=\"binary\", loss=tf.keras.losses.BinaryCrossentropy()):\n",
        "    input_layer = tf.keras.layers.Input(input_shape)\n",
        "\n",
        "    x = input_layer\n",
        "    input_res = input_layer\n",
        "\n",
        "    for d in range(depth):\n",
        "\n",
        "        x = _inception_module(x,kernel_size = kernel_size, bottleneck_size=bottleneck_size, nb_filters=nb_filters)\n",
        "\n",
        "        if use_residual and d % 3 == 2:\n",
        "            x = _shortcut_layer(input_res, x)\n",
        "            input_res = x\n",
        "\n",
        "    gap_layer = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
        "\n",
        "    output_layer = tf.keras.layers.Dense(units=nb_classes,activation='sigmoid')(gap_layer)  \n",
        "    model = tf.keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
        "    model.compile(loss=loss,\n",
        "                  optimizer=tf.keras.optimizers.Adam(learning_rate=lr_init), \n",
        "                  metrics=[tf.keras.metrics.BinaryAccuracy(),\n",
        "                          tf.keras.metrics.AUC(\n",
        "                        num_thresholds=200,\n",
        "                        curve='ROC',\n",
        "                        summation_method='interpolation',\n",
        "                        name=\"ROC\",\n",
        "                        multi_label=True,\n",
        "                        ),\n",
        "                      tf.keras.metrics.AUC(\n",
        "                        num_thresholds=200,\n",
        "                        curve='PR',\n",
        "                        summation_method='interpolation',\n",
        "                        name=\"PRC\",\n",
        "                        multi_label=True,\n",
        "                        )\n",
        "              ])\n",
        "    print(\"Inception model built.\")\n",
        "    return model\n",
        "\n",
        "def scheduler(epoch, lr):\n",
        "    if epoch % 5 == 0:\n",
        "        return lr*0.1\n",
        "    else:\n",
        "        return lr\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEx-BdLJ5oSh",
        "outputId": "34f8305d-822f-4ecd-b6cc-aa7d0811dfc1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inception model built.\n"
          ]
        }
      ],
      "source": [
        "#from github_repo.code.models.your_model import inception_time_model\n",
        "\n",
        "# change first line in your_model.py to from github_repo.code.models.base_model import ClassificationModel\n",
        "\n",
        "experiment = 'exp0'\n",
        "modelname = 'fastai_xresnet1d101'\n",
        "pretrainedfolder = '../output/'+experiment+'/models/'+modelname+'/'\n",
        "mpath='../output/' # <=== path where the finetuned model will be stored\n",
        "n_classes_pretrained = 71 # <=== because we load the model from exp0, this should be fixed because this depends the experiment\n",
        "\n",
        "model = inception_time_model(\"tf_inception\", num_classes, sampling_frequency, mpath, input_shape)\n",
        "\n",
        "#model = fastai_model(\n",
        "#    modelname, \n",
        "#    num_classes, \n",
        "#    sampling_frequency, \n",
        "#    mpath, \n",
        "#    input_shape=input_shape, \n",
        "#    pretrainedfolder=pretrainedfolder,\n",
        "#    n_classes_pretrained=n_classes_pretrained, \n",
        "#    pretrained=True,\n",
        "#    epochs_finetuning=2,\n",
        "#)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6dtMWU15oSh"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Preprocess data with pretrained Standardizer\n",
        "\n",
        "Since we standardize inputs to zero mean and unit variance, your custom data needs to be standardized with the respective mean and variance. This is also provided in the respective experiment folder `output/expX/data/standard_scaler.pkl`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "uqSSsK_V5oSh"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "from github_repo.code.utils import utils\n",
        "\n",
        "#standard_scaler = pickle.load(open('./github_repo/output/'+experiment+'/data/standard_scaler.pkl', \"rb\"))\n",
        "\n",
        "#X_grid = utils.apply_standardizer(X_grid, standard_scaler)\n",
        "#X_val = utils.apply_standardizer(X_val, standard_scaler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "lOSQURgFUycV"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler, MultiLabelBinarizer\n",
        "\n",
        "def apply_standardizer(X, ss):\n",
        "    X_tmp = []\n",
        "    for x in X:\n",
        "        x_shape = x.shape\n",
        "        X_tmp.append(ss.transform(x.flatten()[:,np.newaxis]).reshape(x_shape))\n",
        "    X_tmp = np.array(X_tmp)\n",
        "    return X_tmp\n",
        "\n",
        "def preprocess_signals(X_train, X_validation):\n",
        "    # Standardize data such that mean 0 and variance 1\n",
        "    ss = StandardScaler()\n",
        "    ss.fit(np.vstack(X_train).flatten()[:,np.newaxis].astype(float))\n",
        "  \n",
        "    return apply_standardizer(X_train, ss), apply_standardizer(X_validation, ss)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfdlaRZr5oSh"
      },
      "source": [
        "# Finetune model\n",
        "\n",
        "Calling `model.fit` of a model with `pretrained=True` will perform finetuning as proposed in our work i.e. **gradual unfreezing and discriminative learning rates**. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PlLyg3zHQVFh",
        "outputId": "303f11c5-56c8-459b-f1de-0ba2c6e6e0ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All devices:  [LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:0', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:1', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:2', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:3', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:4', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:5', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:6', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:7', device_type='TPU')]\n"
          ]
        }
      ],
      "source": [
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "# This is the TPU initialization code that has to be at the beginning.\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "print(\"All devices: \", tf.config.list_logical_devices('TPU'))\n",
        "strategy = tf.distribute.TPUStrategy(resolver)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "MxzCOgaP5oSi",
        "outputId": "bd27baac-c15c-47eb-b590-07aa31a3777d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running gridsearch nr 436 of 972...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "df_grid = pd.read_csv(\"/content/drive/MyDrive/ptb-xl-gridsearch/gridsearch_params.csv\")\n",
        "df_score = pd.read_csv(\"/content/drive/MyDrive/ptb-xl-gridsearch/gridsearch_score_all.csv\")\n",
        "gs_left = df_grid.shape[0] - df_score.shape[0] # run only the remaining gridsearch\n",
        "init_rows = df_score.shape[0]\n",
        "\n",
        "for gsr in range(gs_left):\n",
        "  gsr = gsr + init_rows #if previous gridsearch results exists\n",
        "  print(\"Running gridsearch nr {} of {}...\".format(gsr,df_grid.shape[0]))\n",
        "  auc_score = []\n",
        "  for i, (train_index, test_index) in enumerate(skf.split(X_grid, y_grid.argmax(axis=1))):\n",
        "    with strategy.scope():\n",
        "      model = inception_time_model(name=\"tf_inception\", n_classes=num_classes, sampling_frequency=sampling_frequency, outputfolder=mpath, input_shape=input_shape, \n",
        "                                epoch=int(df_grid.iloc[gsr][\"epochs\"]), batch_size=int(df_grid.iloc[gsr][\"batch_size\"]), lr_init = df_grid.iloc[gsr][\"init_lr\"],\n",
        "                                lr_red=df_grid.iloc[gsr][\"lr_red\"], model_depth=int(df_grid.iloc[gsr][\"model_depth\"]), loss=df_grid.iloc[gsr][\"loss\"], \n",
        "                                kernel_size=int(df_grid.iloc[gsr][\"kernel_size\"].split(\",\")[0].split(\"(\")[1]))\n",
        "      cv_x_train = X_grid[train_index]\n",
        "      cv_y_train = y_grid[train_index] \n",
        "      cv_x_test = X_grid[test_index]\n",
        "      cv_y_test = y_grid[test_index]\n",
        "      cv_x_train,cv_x_test = preprocess_signals(cv_x_train,cv_x_test)\n",
        "      \n",
        "      tf_dataset_train = tf.data.Dataset.from_tensor_slices((cv_x_train, cv_y_train))  #tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
        "      tf_dataset_train = tf_dataset_train.cache()\n",
        "      tf_dataset_train = tf_dataset_train.batch(int(df_grid.iloc[gsr][\"batch_size\"]))\n",
        "      tf_dataset_train = tf_dataset_train.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "      tf_dataset_val = tf.data.Dataset.from_tensor_slices((cv_x_test, cv_y_test))\n",
        "      tf_dataset_val = tf_dataset_train.cache()\n",
        "      tf_dataset_val = tf_dataset_train.batch(int(df_grid.iloc[gsr][\"batch_size\"]))\n",
        "      tf_dataset_val = tf_dataset_train.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "      model.fit_tf(tf_dataset_train, tf_dataset_val)\n",
        "      y_hat_test = model.predict(cv_x_test)\n",
        "      score=utils.evaluate_experiment(np.vstack([cv_y_test,np.ones(cv_y_test.shape[1])]), np.vstack([y_hat_test,np.ones(y_hat_test.shape[1])]))\n",
        "      auc_score.append(score)\n",
        "      print(\"Score CV {} : {} (AUROC score)\".format(i+1,score))\n",
        "  df_grid.loc[gsr, 'auc'] = np.asarray(auc_score).mean()\n",
        "  df_score=df_score.append(df_grid.loc[gsr])\n",
        "  df_score.to_csv(\"/content/drive/MyDrive/ptb-xl-gridsearch/gridsearch_score_all.csv\", index=False)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "SPSC9F4wPf9J"
      },
      "outputs": [],
      "source": [
        "utils.utils.evaluate_experiment(np.vstack([cv_y_test,np.ones(cv_y_test.shape[1])]), np.vstack([y_hat_test,np.ones(y_hat_test.shape[1])]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvnNlyCX5oSi"
      },
      "source": [
        "# Evaluate model on validation data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "m1rgPocD5oSi"
      },
      "outputs": [],
      "source": [
        "y_val_pred = model.predict(X_val)\n",
        "utils.evaluate_experiment(y_val, y_val_pred)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.7.4 64-bit ('ecg_python37': conda)",
      "language": "python",
      "name": "python37464bitecgpython37condacca13046f89242bdbe235da55b7380ab"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}